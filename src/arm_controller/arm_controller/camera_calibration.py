#!/usr/bin/env python3
"""
Camera-to-Arm Calibration Tool

Interactive utility that maps camera pixels → arm workspace coordinates.
You place the arm's gripper at 4 known positions in the camera view,
and it computes a homography matrix used by pick_place_node.

Usage:
    ros2 run arm_controller camera_calibration

Steps:
    1. Start camera_node first
    2. Run this tool — a window shows the live camera feed
    3. Click 4 points in the image where you will place the gripper
    4. For each point, move the arm to that pixel location and enter
       the arm's (x, y) position in metres (from the GUI or by reading
       the IK solver output)
    5. The tool computes and saves the homography to a .json file

The homography maps normalised image coordinates (0-1, 0-1) to arm
coordinates (metres in the arm base frame).
"""

import numpy as np
import json
import os
import sys
import time

try:
    import cv2
    OPENCV_AVAILABLE = True
except ImportError:
    OPENCV_AVAILABLE = False

try:
    import rclpy
    from rclpy.node import Node
    from sensor_msgs.msg import Image
    ROS_AVAILABLE = True
except ImportError:
    ROS_AVAILABLE = False


CALIBRATION_DIR = os.path.dirname(os.path.abspath(__file__))
DEFAULT_OUTPUT = os.path.join(CALIBRATION_DIR, 'camera_calibration.json')


class CalibrationCollector:
    """Collects point correspondences for homography computation."""

    def __init__(self):
        self.image_points = []   # (normalised x, normalised y)
        self.arm_points = []     # (x_metres, y_metres)
        self.latest_frame = None
        self.click_point = None
        self.image_w = 640
        self.image_h = 480

    def mouse_callback(self, event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            self.click_point = (x, y)
            print(f'  Clicked pixel: ({x}, {y})')

    def add_point(self, pixel_x, pixel_y, arm_x, arm_y):
        nx = pixel_x / self.image_w
        ny = pixel_y / self.image_h
        self.image_points.append((nx, ny))
        self.arm_points.append((arm_x, arm_y))
        print(f'  Point {len(self.image_points)}: '
              f'pixel_norm=({nx:.3f}, {ny:.3f}) → arm=({arm_x:.4f}, {arm_y:.4f})')

    def compute_homography(self):
        """Compute 3×3 homography from ≥4 point pairs."""
        if len(self.image_points) < 4:
            print('Need at least 4 points!')
            return None

        src = np.array(self.image_points, dtype=np.float64)
        dst = np.array(self.arm_points, dtype=np.float64)

        H, status = cv2.findHomography(src, dst, cv2.RANSAC, 5.0)
        if H is None:
            print('Homography computation failed!')
            return None

        print('\nHomography matrix:')
        print(H)

        # Test: show mapping for all calibration points
        print('\nVerification:')
        for i in range(len(src)):
            pt = np.array([src[i][0], src[i][1], 1.0])
            mapped = H @ pt
            mapped /= mapped[2]
            err = np.sqrt((mapped[0] - dst[i][0])**2 + (mapped[1] - dst[i][1])**2)
            print(f'  Point {i+1}: expected ({dst[i][0]:.4f}, {dst[i][1]:.4f}), '
                  f'got ({mapped[0]:.4f}, {mapped[1]:.4f}), error={err*1000:.1f} mm')

        return H

    def save(self, path, H):
        """Save homography and point pairs to JSON."""
        data = {
            'homography': H.tolist(),
            'image_points_norm': self.image_points,
            'arm_points_metres': self.arm_points,
            'image_size': [self.image_w, self.image_h],
            'notes': 'Generated by camera_calibration.py',
        }
        with open(path, 'w') as f:
            json.dump(data, f, indent=2)
        print(f'\nCalibration saved to: {path}')


class CalibrationNode(Node):
    """ROS2 node that subscribes to /camera/image_raw for calibration."""

    def __init__(self, collector):
        super().__init__('camera_calibration')
        self.collector = collector
        self.sub = self.create_subscription(
            Image, '/camera/image_raw', self.image_callback, 10
        )
        self.get_logger().info('Waiting for camera frames on /camera/image_raw...')

    def image_callback(self, msg):
        try:
            if msg.encoding == 'rgb8':
                frame = np.frombuffer(msg.data, dtype=np.uint8).reshape(
                    msg.height, msg.width, 3
                )
                frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
            elif msg.encoding == 'bgr8':
                frame = np.frombuffer(msg.data, dtype=np.uint8).reshape(
                    msg.height, msg.width, 3
                )
            else:
                return
            self.collector.latest_frame = frame
            self.collector.image_w = msg.width
            self.collector.image_h = msg.height
        except Exception:
            pass


def run_interactive_calibration():
    """Interactive calibration using ROS2 camera feed + OpenCV window."""
    if not OPENCV_AVAILABLE:
        print('ERROR: opencv-python is required. Install with: pip install opencv-python')
        return
    if not ROS_AVAILABLE:
        print('ERROR: rclpy is required. Source ROS2 first.')
        return

    rclpy.init()
    collector = CalibrationCollector()
    node = CalibrationNode(collector)

    cv2.namedWindow('Calibration')
    cv2.setMouseCallback('Calibration', collector.mouse_callback)

    print('\n' + '=' * 60)
    print('  CAMERA-TO-ARM CALIBRATION')
    print('=' * 60)
    print('\nInstructions:')
    print('  1. You will select 4+ points in the camera image')
    print('  2. For each point, move the arm gripper to that position')
    print('  3. Enter the arm coordinates (x, y in metres) for each')
    print('  4. The tool computes a mapping from camera → arm')
    print('\nTip: Use the GUI or "ros2 topic echo /joint_states" to ')
    print('read the arm position. Use the IK solver for coordinates.')
    print('\nPress "c" to capture a point, "q" when done (min 4 points)')
    print('=' * 60 + '\n')

    try:
        while rclpy.ok():
            rclpy.spin_once(node, timeout_sec=0.05)

            if collector.latest_frame is not None:
                display = collector.latest_frame.copy()

                # Draw existing calibration points
                for i, (nx, ny) in enumerate(collector.image_points):
                    px = int(nx * collector.image_w)
                    py = int(ny * collector.image_h)
                    cv2.circle(display, (px, py), 8, (0, 255, 0), 2)
                    cv2.putText(display, f'P{i+1}', (px + 10, py - 5),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

                # Draw click point
                if collector.click_point:
                    cv2.circle(display, collector.click_point, 10, (0, 0, 255), 2)
                    cv2.drawMarker(display, collector.click_point, (0, 0, 255),
                                   cv2.MARKER_CROSS, 20, 2)

                # Status text
                n = len(collector.image_points)
                status = f'Points: {n}/4+  |  Click point, press C to capture, Q to finish'
                cv2.putText(display, status, (10, 25),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.55, (255, 255, 255), 1)

                cv2.imshow('Calibration', display)

            key = cv2.waitKey(30) & 0xFF

            if key == ord('c') and collector.click_point:
                px, py = collector.click_point
                print(f'\n  Pixel selected: ({px}, {py})')
                try:
                    arm_x = float(input('  Enter arm X (metres): '))
                    arm_y = float(input('  Enter arm Y (metres): '))
                    collector.add_point(px, py, arm_x, arm_y)
                    collector.click_point = None
                except ValueError:
                    print('  Invalid input — skipping point')

            elif key == ord('q'):
                if len(collector.image_points) >= 4:
                    break
                else:
                    print(f'  Need at least 4 points (have {len(collector.image_points)})')

    except KeyboardInterrupt:
        pass

    cv2.destroyAllWindows()

    # Compute and save
    if len(collector.image_points) >= 4:
        H = collector.compute_homography()
        if H is not None:
            output_path = DEFAULT_OUTPUT
            collector.save(output_path, H)
            print(f'\nUse this calibration with pick_place_node:')
            print(f'  ros2 run arm_controller pick_place_node '
                  f'--ros-args -p calibration_file:={output_path}')
    else:
        print('\nNot enough points — calibration cancelled')

    node.destroy_node()
    rclpy.shutdown()


def run_manual_calibration():
    """Calibration without live camera — enter points manually."""
    print('\n' + '=' * 60)
    print('  MANUAL CALIBRATION (no camera feed)')
    print('=' * 60)
    print('\nEnter at least 4 point correspondences.')
    print('Image coords are normalised (0.0 - 1.0).\n')

    collector = CalibrationCollector()

    while True:
        n = len(collector.image_points) + 1
        print(f'--- Point {n} ---')
        try:
            nx = float(input('  Image X (0-1): '))
            ny = float(input('  Image Y (0-1): '))
            ax = float(input('  Arm X (metres): '))
            ay = float(input('  Arm Y (metres): '))
            collector.image_points.append((nx, ny))
            collector.arm_points.append((ax, ay))
        except ValueError:
            print('  Invalid input')
            continue

        if len(collector.image_points) >= 4:
            more = input('  Add more points? (y/n): ').strip().lower()
            if more != 'y':
                break

    if OPENCV_AVAILABLE:
        H = collector.compute_homography()
        if H is not None:
            collector.save(DEFAULT_OUTPUT, H)
    else:
        print('OpenCV required for homography computation')


def main():
    if OPENCV_AVAILABLE and ROS_AVAILABLE:
        run_interactive_calibration()
    else:
        print('Running in manual mode (no OpenCV/ROS2)')
        run_manual_calibration()


if __name__ == '__main__':
    main()
